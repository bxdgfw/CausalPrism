{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "删掉负值，随机系数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd  \n",
    "import time\n",
    "\n",
    "def generate_data(n_samples, p):  \n",
    "    np.random.seed(1)  \n",
    "      \n",
    "    X = np.random.normal(0, 1, size=(n_samples, p))     \n",
    "    X = np.around(X, 2)    \n",
    "  \n",
    "    coefs_T = np.random.uniform(0, 0.5, size=p)    \n",
    "    coefs_T = np.around(coefs_T, 2)    \n",
    "    log_odds = np.dot(X, coefs_T) + np.random.uniform(-1, 1, size=n_samples)     \n",
    "    T_sigmoid = 1/(1 + np.exp(-log_odds))        \n",
    "    T = np.array([np.random.binomial(1, p) for p in T_sigmoid])    \n",
    "  \n",
    "    coefs_TE = np.random.uniform(0, 2, size=p)    \n",
    "    coefs_TE = np.around(coefs_TE, 2)    \n",
    "    TE = np.dot(np.maximum(X[:, :], 0), coefs_TE) + np.random.uniform(-1, 1, size=n_samples)    \n",
    "    TE = np.around(TE, 2)    \n",
    "    coefs_Y = np.random.uniform(0, 1, size = p)    \n",
    "    Y = TE * T + np.dot(X, coefs_Y) + np.random.uniform(-1, 1, size=n_samples)      \n",
    "    Y = np.around(Y, 2)    \n",
    "    offset =  np.abs(np.min(Y))    \n",
    "    Y = Y + offset    \n",
    "  \n",
    "    e = T_sigmoid    \n",
    "    wt = np.around(T/e + (1-T)/(1-e), 2)    \n",
    "  \n",
    "    df = pd.DataFrame(X, columns=[f'X{i+1}' for i in range(p)])     \n",
    "    df['t'] = T      \n",
    "    df['TE'] = TE     \n",
    "    df['y'] = Y     \n",
    "    df['e'] = e    \n",
    "    df['wt'] = wt    \n",
    "    df['v'] = np.around(wt*Y, 2)    \n",
    "  \n",
    "    cols = [f'X{i+1}' for i in range(1, p)]      \n",
    "    df[cols] = df[cols].astype(float)     \n",
    "  \n",
    "    return df  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 固定一个参数测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_list = [1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000, 11000, 12000, 13000, 14000, 15000, 16000, 17000, 18000, 19000, 20000, 21000, 22000, 23000, 24000, 25000]  \n",
    "p_list = [10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100, 105, 110, 115, 120, 125, 130, 135, 140, 145, 150]  \n",
    "  \n",
    "# 用于记录结果的字典  \n",
    "results_n_samples = {\"n_samples\": [], \"time\": []}  \n",
    "results_p = {\"p\": [], \"time\": []}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import baseline\n",
    "\n",
    "# 固定p，改变n_samples  \n",
    "fixed_p = 20  # 可以选择你想固定的p值  \n",
    "for n_samples in n_samples_list:  \n",
    "    df = generate_data(n_samples, fixed_p)  \n",
    "    df_ori = df.copy()\n",
    "    \n",
    "    covariate_columns = [f'X{i+1}' for i in range(fixed_p)]\n",
    "\n",
    "    result = baseline.pymoo_opt(df_ori, covariate_columns, \"t\", 'y', cov_ratio = 0.03, length_limit = 4)\n",
    "    elapsed_time = result[\"time\"]\n",
    "  \n",
    "    results_n_samples[\"n_samples\"].append(n_samples)  \n",
    "    results_n_samples[\"time\"].append(elapsed_time)  \n",
    "  \n",
    "# 固定n_samples，改变p  \n",
    "fixed_n_samples = 2000  # 可以选择你想固定的n_samples值  \n",
    "for p in p_list:  \n",
    "    df = generate_data(fixed_n_samples, p)  \n",
    "    df_ori = df.copy()\n",
    "\n",
    "    covariate_columns = [f'X{i+1}' for i in range(p)]\n",
    "\n",
    "    result = baseline.pymoo_opt(df_ori, covariate_columns, \"t\", 'y', cov_ratio = 0.03, length_limit = 4)\n",
    "    elapsed_time = result[\"time\"]  \n",
    "  \n",
    "    results_p[\"p\"].append(p)  \n",
    "    results_p[\"time\"].append(elapsed_time)   \n",
    "  \n",
    "# 将结果转换为DataFrame并保存为CSV文件  \n",
    "results_df_n_samples = pd.DataFrame(results_n_samples)  \n",
    "results_df_n_samples.to_csv(\"result/scalability_test_results_n_samples.csv\", index=False)  \n",
    "  \n",
    "results_df_p = pd.DataFrame(results_p)  \n",
    "results_df_p.to_csv(\"result/scalability_test_results_p.csv\", index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  \n",
    "  \n",
    "# 从CSV文件中读取结果  \n",
    "results_df_n_samples = pd.read_csv(\"result/scalability_test_results_n_samples.csv\")  \n",
    "results_df_p = pd.read_csv(\"result/scalability_test_results_p.csv\")  \n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(10, 10))  \n",
    "  \n",
    "# 子图1：训练时间 vs 数据集大小  \n",
    "ax[0].plot(results_df_n_samples[\"n_samples\"], results_df_n_samples[\"time\"], marker='o')  \n",
    "ax[0].set_xlabel('Number of Samples')  \n",
    "ax[0].set_ylabel('Training Time')  \n",
    "ax[0].set_title(f'Training Time vs Number of Samples (p={20})')  \n",
    "  \n",
    "# 子图2：训练时间 vs 协变量数量  \n",
    "ax[1].plot(results_df_p[\"p\"], results_df_p[\"time\"], marker='o')  \n",
    "ax[1].set_xlabel('Number of Covariates')  \n",
    "ax[1].set_ylabel('Training Time')  \n",
    "ax[1].set_title(f'Training Time vs Number of Covariates (n_samples={2000})')  \n",
    "  \n",
    "plt.tight_layout()  \n",
    "\n",
    "# 保存图像  \n",
    "plt.savefig(\"scalability.svg\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多次测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd  \n",
    "import time\n",
    "\n",
    "def generate_data(n_samples, p, seed):  \n",
    "    np.random.seed(seed)  \n",
    "      \n",
    "    X = np.random.normal(0, 1, size=(n_samples, p))     \n",
    "    X = np.around(X, 2)    \n",
    "  \n",
    "    coefs_T = np.random.uniform(0, 0.5, size=p)    \n",
    "    coefs_T = np.around(coefs_T, 2)    \n",
    "    log_odds = np.dot(X, coefs_T) + np.random.uniform(-1, 1, size=n_samples)     \n",
    "    T_sigmoid = 1/(1 + np.exp(-log_odds))        \n",
    "    T = np.array([np.random.binomial(1, p) for p in T_sigmoid])    \n",
    "  \n",
    "    coefs_TE = np.random.uniform(0, 2, size=p)    \n",
    "    coefs_TE = np.around(coefs_TE, 2)    \n",
    "    TE = np.dot(np.maximum(X[:, :], 0), coefs_TE) + np.random.uniform(-1, 1, size=n_samples)    \n",
    "    TE = np.around(TE, 2)    \n",
    "    coefs_Y = np.random.uniform(0, 1, size = p)    \n",
    "    Y = TE * T + np.dot(X, coefs_Y) + np.random.uniform(-1, 1, size=n_samples)      \n",
    "    Y = np.around(Y, 2)    \n",
    "    offset =  np.abs(np.min(Y))    \n",
    "    Y = Y + offset    \n",
    "  \n",
    "    e = T_sigmoid    \n",
    "    wt = np.around(T/e + (1-T)/(1-e), 2)    \n",
    "  \n",
    "    df = pd.DataFrame(X, columns=[f'X{i+1}' for i in range(p)])     \n",
    "    df['t'] = T      \n",
    "    df['TE'] = TE     \n",
    "    df['y'] = Y     \n",
    "    df['e'] = e    \n",
    "    df['wt'] = wt    \n",
    "    df['v'] = np.around(wt*Y, 2)    \n",
    "  \n",
    "    cols = [f'X{i+1}' for i in range(1, p)]      \n",
    "    df[cols] = df[cols].astype(float)     \n",
    "  \n",
    "    return df  \n",
    "\n",
    "n_samples_list = [1000, 2000, 3000]  \n",
    "p_list = [10, 12, 14]  \n",
    "  \n",
    "# 用于记录结果的字典  \n",
    "results_n_samples = {\"n_samples\": [], \"time\": [], \"std\": [], \"all_times\": []}    \n",
    "results_p = {\"p\": [], \"time\": [], \"std\": [], \"all_times\": []}  \n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    " \n",
    "\n",
    "# 固定p，改变n_samples    \n",
    "fixed_p = 20  # 可以选择你想固定的p值    \n",
    "for n_samples in n_samples_list:    \n",
    "    times = []  # 用于存储每次实验的时间  \n",
    "    for i in range(5):  # 进行十次实验  \n",
    "        df = generate_data(n_samples, fixed_p)  \n",
    "        df_ori = df.copy()\n",
    "        \n",
    "        covariate_columns = [f'X{i+1}' for i in range(fixed_p)]\n",
    "        \n",
    "        result = baseline.pymoo_opt(df_ori, covariate_columns, \"t\", 'y', cov_ratio = 0.03, length_limit = 4)\n",
    "        elapsed_time = result[\"time\"]    \n",
    "        times.append(elapsed_time)  # 添加到列表中  \n",
    "    \n",
    "    avg_time = np.mean(times)  # 计算平均时间    \n",
    "    std_time = np.std(times)  # 计算标准差  \n",
    "    results_n_samples[\"n_samples\"].append(n_samples)      \n",
    "    results_n_samples[\"time\"].append(avg_time)  # 添加平均时间到结果中  \n",
    "    results_n_samples[\"std\"].append(std_time)  # 添加标准差到结果中  \n",
    "    results_n_samples[\"all_times\"].append(times)  # 添加所有时间到结果中  \n",
    "    \n",
    "# 固定n_samples，改变p    \n",
    "fixed_n_samples = 2000  # 可以选择你想固定的n_samples值    \n",
    "for p in p_list:    \n",
    "    times = []  # 用于存储每次实验的时间  \n",
    "    for i in range(5):  # 进行十次实验  \n",
    "        df = generate_data(n_samples, fixed_p)  \n",
    "        df_ori = df.copy()\n",
    "        \n",
    "        covariate_columns = [f'X{i+1}' for i in range(fixed_p)]\n",
    "        \n",
    "        result = baseline.pymoo_opt(df_ori, covariate_columns, \"t\", 'y', cov_ratio = 0.03, length_limit = 4)\n",
    "        elapsed_time = result[\"time\"]    \n",
    "        times.append(elapsed_time)  # 添加到列表中  \n",
    "    \n",
    "    avg_time = np.mean(times)  # 计算平均时间    \n",
    "    std_time = np.std(times)  # 计算标准差  \n",
    "    results_p[\"p\"].append(p)      \n",
    "    results_p[\"time\"].append(avg_time)  # 添加平均时间到结果中  \n",
    "    results_p[\"std\"].append(std_time)  # 添加标准差到结果中  \n",
    "    results_p[\"all_times\"].append(times)  # 添加所有时间到结果中 \n",
    "  \n",
    "# 将结果转换为DataFrame并保存为CSV文件  \n",
    "results_df_n_samples = pd.DataFrame(results_n_samples)  \n",
    "results_df_n_samples.to_csv(\"scalability_test_results_n_samples_demo.csv\", index=False)  \n",
    "  \n",
    "results_df_p = pd.DataFrame(results_p)  \n",
    "results_df_p.to_csv(\"scalability_test_results_p_demo.csv\", index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建两个子图    \n",
    "fig, ax = plt.subplots(2, 1, figsize=(10, 10))    \n",
    "  \n",
    "# 子图1：训练时间 vs 数据集大小    \n",
    "ax[0].errorbar(results_df_n_samples[\"n_samples\"], results_df_n_samples[\"time\"], yerr=results_df_n_samples[\"std\"], fmt='-o', capsize=5)  \n",
    "ax[0].set_xlabel('Number of Samples')    \n",
    "ax[0].set_ylabel('Training Time')    \n",
    "ax[0].set_title(f'Training Time vs Number of Samples (p={fixed_p})')    \n",
    "  \n",
    "# 子图2：训练时间 vs 协变量数量    \n",
    "ax[1].errorbar(results_df_p[\"p\"], results_df_p[\"time\"], yerr=results_df_p[\"std\"], fmt='-o', capsize=5)  \n",
    "ax[1].set_xlabel('Number of Covariates')    \n",
    "ax[1].set_ylabel('Training Time')    \n",
    "ax[1].set_title(f'Training Time vs Number of Covariates (n_samples={fixed_n_samples})')    \n",
    "  \n",
    "plt.tight_layout()    \n",
    "  \n",
    "# 保存图像    \n",
    "plt.savefig(\"scalability_with_std.svg\")    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
